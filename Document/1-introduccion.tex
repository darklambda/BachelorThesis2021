\secnumberlesssection{INTRODUCCIÓN}

En los últimos años, términos como \textit{Machine Learning} o \textit{Data Mining} han sido protagónicos en el área de la ciencia de la computación por su aplicabilidad a la hora de abordar problemas complejos.
%por un aumento en su uso/empleo a la hora de resolver problemas complejos.
Sin embargo, el problema de trabajar con estos campos es la dificultad de su escalabilidad, al requerir un gran tamaño de operaciones elementales, lo cual significa que se debe utilizar bibliotecas y hardware especializado para poder abordar estos problemas.
Por otro lado, al tratar de compensar esto último es que se ha aplicado la Computación de Alto Rendimiento (del inglés, High Performance Computing), que cual consiste en el uso de clústeres de nodos computacionales, supercomputadores o programación paralela para la solución de aquellos problemas de ingeniería, ciencia o gestión que necesitan de un alto rendimiento.

Debido al avance de la tecnología y con tal de beneficiar el uso de la Computación de Alto Desempeño es que desde el inicio de la década se ha empezado a utilizar el potencial computacional de Unidades de Procesamiento Gráfica (del inglés, Graphic Processing Unit o GPU) por sobre las Unidades de Procesamiento Central (del inglés, Central Processing Unit o CPU) debido a la arquitectura que poseen. 
En particular, esto es por que una CPU está diseñada para manejar rápidamente una gama amplia de tareas, mientras que una GPU está diseñada originalmente para el renderizado de imágenes y videos en alta resolución \cite{gpu}, lo cual sumado a la gran cantidad de unidades de procesamiento de GPUs, presenta la posibilidad del uso dedicado de estas en programación paralela.
Por esto, es que se ha preferido el uso de GPUs al momento de realizar tareas de alto desempeño, ya que el rendimiento en términos de la cantidad de operaciones de punto flotante por segundo (del ingles, Floating-Point Operation per Second o FLOPs) es mucho mayor en tarjetas de procesamiento gráfico que de procesamiento central, tomando en cuenta componentes con características parecidas.
Esta diferencia en el rendimiento se debe principalmente, a que si bien una GPU posee una velocidad de reloj interno mucho menor al de una CPU, su cantidad de unidades de procesamiento es mucho mayor, generando mejores resultados en aplicaciones a problemas que sacan ventaja de la programación paralela.

Las simulaciones computacionales, corresponden a programas informáticos cuyo fin es poder simular situaciones en base a modelos de distintas áreas de estudio.
Aquellas simulaciones físicas con menos probabilidad de ocurrencia, tales como tsunamis o huracanes, son en las que hay un mayor enfoque pues normalmente son las que más importancia e impacto producen sobre la vida cotidiana.
La simulación de lo anterior, depende además de la forma en que se modele el problema deseado, el tipo de escala que se utilice y las condiciones de borde que se planteen.

En esta memoria, se presentará una implementación de la simulación computacional de tsunamis utilizando ROCm, una plataforma de desarrollo relativamente nueva de la compañía estadounidense de semi conductores AMD~\cite{rocm}, la cual permite la ejecución de código en GPU sobre tarjetas de la misma marca, lo cual permitirá realizar tanto una comparativa entre el rendimiento de los componentes utilizados como la creación instancias de simulaciones de dinámica de fluidos en términos de lo que sería el inicio de un tsunami. 

La estructura de esta memoria es la siguiente; el Capítulo~\hyperref[sec:1]{1} presentará la definición del problema a tratar y una descripción de de las tecnologías a utilizar; el Capítulo~\hyperref[sec:2]{2} hará una revisión general del estado del arte sobre el uso de ROCm en investigaciones; en el Capítulo~\hyperref[sec:3]{3} se explicará la teoría detrás del trabajo realizado; el Capítulo~\hyperref[sec:4]{4} expondrá los resultados de las experimentaciones propuestas y en el Capítulo~\hyperref[sec:5]{5} se harán conclusiones respecto al trabajo realizado.
